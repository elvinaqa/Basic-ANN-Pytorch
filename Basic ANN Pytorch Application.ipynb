{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0             5.1          3.5           1.4          0.2       0\n",
       "1             4.9          3.0           1.4          0.2       0\n",
       "2             4.7          3.2           1.3          0.2       0\n",
       "3             4.6          3.1           1.5          0.2       0\n",
       "4             5.0          3.6           1.4          0.2       0\n",
       "..            ...          ...           ...          ...     ...\n",
       "145           6.7          3.0           5.2          2.3       2\n",
       "146           6.3          2.5           5.0          1.9       2\n",
       "147           6.5          3.0           5.2          2.0       2\n",
       "148           6.2          3.4           5.4          2.3       2\n",
       "149           5.9          3.0           5.1          1.8       2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = le.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df.drop('target', axis=1).values\n",
    "label = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.LongTensor(y_train).reshape(-1, 1)\n",
    "y_test = torch.LongTensor(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second way\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop('target', axis=1).values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_test_split\n",
    "iris = TensorDataset(torch.FloatTensor(data), torch.LongTensor(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in iris:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_loader = DataLoader(iris, batch_size=50, shuffle=True)\n",
    "# gonna make 3 batches\n",
    "# 150/3 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1ff42dec608>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000]]), tensor([0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 2, 1, 1, 2, 0, 2, 0, 0, 1, 0, 1, 2, 1,\n",
      "        1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 0, 0, 1, 0, 1, 0, 2, 2, 2, 0, 1,\n",
      "        0, 1])]\n",
      "1 [tensor([[5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000]]), tensor([0, 1, 2, 1, 2, 2, 1, 0, 2, 2, 2, 1, 2, 1, 0, 2, 0, 2, 0, 1, 0, 0, 1, 2,\n",
      "        1, 1, 0, 1, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 1, 2,\n",
      "        1, 2])]\n",
      "2 [tensor([[5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000]]), tensor([1, 2, 1, 2, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2,\n",
      "        2, 0, 1, 0, 2, 2, 1, 0, 1, 1, 0, 0, 2, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0,\n",
      "        1, 0])]\n"
     ]
    }
   ],
   "source": [
    "for i_batch, smp_batch in enumerate(iris_loader):\n",
    "    print(i_batch, smp_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000]]), tensor([2, 1, 0, 1, 0, 2, 2, 0, 0, 2, 1, 2, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 2])]\n",
      "[tensor([[6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000]]), tensor([2, 0, 2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 2, 0, 1, 2, 2,\n",
      "        1, 0, 2, 1, 1, 2, 2, 0, 1, 0, 0, 0, 2, 2, 2, 2, 0, 1, 1, 1, 2, 0, 0, 2,\n",
      "        0, 2])]\n",
      "[tensor([[4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000]]), tensor([0, 0, 2, 0, 1, 1, 1, 0, 0, 2, 0, 0, 2, 1, 2, 1, 2, 2, 0, 2, 1, 1, 1, 1,\n",
      "        0, 2, 1, 2, 2, 2, 0, 1, 2, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0,\n",
      "        0, 0])]\n"
     ]
    }
   ],
   "source": [
    "for i in iris_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Class\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        # layers\n",
    "        # input(4 features) hidden(n) hidden(3) output(3 classes)\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward propogation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "torch.manual_seed(32) #prevent weight and bias randomization \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss (error)\n",
    "# crossentropy for multiclass classification problem\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# feeding model layers and learning rate to optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1).values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
    "testloader = DataLoader(X_test, batch_size=60, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 1.15071154\n",
      "epoch: 11  loss: 0.93773156\n",
      "epoch: 21  loss: 0.77982575\n",
      "epoch: 31  loss: 0.60994011\n",
      "epoch: 41  loss: 0.40079927\n",
      "epoch: 51  loss: 0.25436318\n",
      "epoch: 61  loss: 0.15053058\n",
      "epoch: 71  loss: 0.10086945\n",
      "epoch: 81  loss: 0.08128312\n",
      "epoch: 91  loss: 0.07231427\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the model in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # telling pytorch to not train on test (dont change gradients(weights and bias) based on test, we are just testing now)\n",
    "    # reduced memory usage, speeded up computation - it is evaluation, not backpropogation\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0581)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss\n",
    "# good performance - not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([-2.1252,  4.8064, -0.8628]) answer is 4.806390762329102 1\n",
      "2.) tensor([-1.7985,  5.3098, -1.5449]) answer is 5.309832572937012 1\n",
      "3.) tensor([  6.3542,   0.8438, -10.0541]) answer is 6.354162693023682 0\n",
      "4.) tensor([-3.9123,  4.5958,  1.1693]) answer is 4.595773696899414 1\n",
      "5.) tensor([-7.4713,  3.2021,  5.7853]) answer is 5.785310745239258 2\n",
      "6.) tensor([-10.4976,   1.6459,   9.6297]) answer is 9.629681587219238 2\n",
      "7.) tensor([  6.3201,   0.9917, -10.1532]) answer is 6.320135593414307 0\n",
      "8.) tensor([  7.0468,   0.7059, -10.9137]) answer is 7.046820163726807 0\n",
      "9.) tensor([-7.2061,  3.3477,  5.3565]) answer is 5.3564677238464355 2\n",
      "10.) tensor([-9.3960,  2.5759,  8.1033]) answer is 8.103338241577148 2\n",
      "11.) tensor([-9.8808,  2.3475,  8.7141]) answer is 8.714097023010254 2\n",
      "12.) tensor([ 6.2748,  0.6655, -9.7613]) answer is 6.274759292602539 0\n",
      "13.) tensor([-9.3142,  2.1880,  8.1947]) answer is 8.194701194763184 2\n",
      "14.) tensor([-3.7803,  4.5050,  1.0752]) answer is 4.505033493041992 1\n",
      "15.) tensor([-7.8657,  3.0117,  6.2303]) answer is 6.230347633361816 2\n",
      "16.) tensor([-1.8867,  5.1572, -1.3345]) answer is 5.157235145568848 1\n",
      "17.) tensor([-5.7006,  3.5030,  3.6696]) answer is 3.669628620147705 2\n",
      "18.) tensor([  7.1789,   0.7369, -11.1350]) answer is 7.17893123626709 0\n",
      "19.) tensor([-3.2944,  4.7931,  0.3475]) answer is 4.793066024780273 1\n",
      "20.) tensor([-7.7665,  3.7629,  5.7095]) answer is 5.709475517272949 2\n",
      "21.) tensor([  6.6499,   0.7889, -10.4252]) answer is 6.649936199188232 0\n",
      "22.) tensor([  7.4357,   0.8918, -11.6600]) answer is 7.435720920562744 0\n",
      "23.) tensor([-9.7584,  2.1744,  8.6654]) answer is 8.665382385253906 2\n",
      "24.) tensor([  6.5770,   0.7421, -10.2733]) answer is 6.577019214630127 0\n",
      "25.) tensor([-7.4144,  2.8719,  5.9445]) answer is 5.944545269012451 2\n",
      "26.) tensor([-6.1551,  3.4031,  4.2300]) answer is 4.229972839355469 2\n",
      "27.) tensor([-3.1634,  4.7460,  0.2703]) answer is 4.745988845825195 1\n",
      "28.) tensor([-1.5446,  4.9031, -1.5557]) answer is 4.903094291687012 1\n",
      "29.) tensor([-7.4335,  3.1101,  5.7350]) answer is 5.734965801239014 2\n",
      "30.) tensor([-6.7037,  3.1187,  4.9595]) answer is 4.959476947784424 2\n",
      "Correct classifications: 30\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f\"{i+1}.) {y_val} answer is {y_val.max()} {y_test[i]}\")\n",
    "        \n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f\"Correct classifications: {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model - learnt params of model\n",
    "torch.save(model.state_dict(), 'iris_torch_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_model = Model()\n",
    "n_model.load_state_dict(torch.load('iris_torch_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = torch.tensor([5.6, 3.7, 2.2, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5.9522,   1.5596, -10.0054])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(n_model(n_data))\n",
    "    print(n_model(n_data).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setosa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
